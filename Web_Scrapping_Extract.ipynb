{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from web(weather) using web scrapping\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the URL\n",
    "URL = \"https://www.timeanddate.com/weather/usa/new-york/historic\"\n",
    "\n",
    "# Send a GET request to fetch the HTML content\n",
    "response = requests.get(URL)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all table rows (<tr> elements)\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "# Find the table containing the weather data (adjust selector based on actual table structure)\n",
    "table = soup.find('table')  # You might need to add specific classes or IDs to locate the correct table\n",
    "\n",
    "# Check if the table is found\n",
    "if table:\n",
    "    # Extract table headers (column names)\n",
    "    headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "    # Print the headers for debugging\n",
    "    print(\"Extracted Headers:\", headers)\n",
    "else:\n",
    "    print(\"Table not found on the webpage.\")\n",
    "\n",
    "\n",
    "# List to store scraped data\n",
    "web_scraped_data = []\n",
    "\n",
    "# Loop through \n",
    "for row in rows[1:]:  # Skip the header row\n",
    "    columns = row.find_all('td')  # Find all table data cells\n",
    "    \n",
    "    if len(columns) >= 7:  # Ensure there are enough columns\n",
    "        try:\n",
    "            # Extract and clean the data for each column\n",
    "            temp = columns[1].text.strip()  \n",
    "            weather = columns[2].text.strip()\n",
    "            wind = columns[3].text.strip()\n",
    "            humidity = columns[5].text.strip()\n",
    "            barometer = columns[6].text.strip()\n",
    "            visibility = columns[7].text.strip()\n",
    "\n",
    "            # Append the data as a dictionary to the list\n",
    "            web_scraped_data.append({\n",
    "                'Temp': temp,\n",
    "                'Weather': weather,\n",
    "                'Wind': wind,\n",
    "                'Humidity': humidity,\n",
    "                'Barometer': barometer,\n",
    "                'Visibility': visibility,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {[col.text.strip() for col in columns]}, Error: {e}\")\n",
    "\n",
    "# Convert the list of dictionaries into a Pandas DataFrame\n",
    "if web_scraped_data:\n",
    "    web_scraping_df = pd.DataFrame(web_scraped_data)\n",
    "    print(web_scraping_df)\n",
    "else:\n",
    "    print(\"No valid data was scraped.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Headers: ['', 'Temperature', 'Humidity', 'Pressure', 'High', 'Low', 'Average']\n",
      "   Time  Temp                     Weather     Wind Humidity Barometer  \\\n",
      "0        6 °C                      Clear.      N/A        ↑       65%   \n",
      "1        6 °C                   Overcast.   9 km/h        ↑       65%   \n",
      "2        6 °C                      Clear.  22 km/h        ↑       68%   \n",
      "3        6 °C             Passing clouds.  19 km/h        ↑       74%   \n",
      "4        6 °C             Passing clouds.  22 km/h        ↑       74%   \n",
      "5        6 °C             Passing clouds.      N/A        ↑       76%   \n",
      "6        6 °C             Passing clouds.  20 km/h        ↑       76%   \n",
      "7        6 °C              Partly cloudy.  19 km/h        ↑       76%   \n",
      "8        6 °C                   Overcast.  20 km/h        ↑       82%   \n",
      "9        7 °C                   Overcast.  20 km/h        ↑       82%   \n",
      "10       7 °C       More clouds than sun.  13 km/h        ↑       80%   \n",
      "11       7 °C                 Low clouds.   7 km/h        ↑       86%   \n",
      "12       8 °C                 Low clouds.   9 km/h        ↑       90%   \n",
      "13       8 °C                        Fog.   6 km/h        ↑       93%   \n",
      "14       8 °C            Light rain. Fog.   7 km/h        ↑       93%   \n",
      "15       9 °C            Light rain. Fog.  No wind        ↑       93%   \n",
      "16       9 °C            Light rain. Fog.  No wind        ↑       93%   \n",
      "17       9 °C            Light rain. Fog.  No wind        ↑       93%   \n",
      "18       9 °C                  Rain. Fog.  No wind        ↑       93%   \n",
      "19       9 °C                  Rain. Fog.   9 km/h        ↑       90%   \n",
      "20       9 °C            Light rain. Fog.  No wind        ↑       93%   \n",
      "21       9 °C            Light rain. Fog.   6 km/h        ↑       90%   \n",
      "22       9 °C            Light rain. Fog.   7 km/h        ↑       93%   \n",
      "23       8 °C                  Rain. Fog.  No wind        ↑       93%   \n",
      "24       8 °C            Heavy rain. Fog.   9 km/h        ↑       93%   \n",
      "25       8 °C                  Rain. Fog.  No wind        ↑       93%   \n",
      "26       7 °C                  Rain. Fog.  No wind        ↑       90%   \n",
      "27       7 °C            Light rain. Fog.  13 km/h        ↑       90%   \n",
      "28       7 °C            Light rain. Fog.   7 km/h        ↑       90%   \n",
      "29       7 °C                  Rain. Fog.  13 km/h        ↑       90%   \n",
      "30       7 °C            Light rain. Fog.  11 km/h        ↑       89%   \n",
      "31       7 °C            Light rain. Fog.   6 km/h        ↑       85%   \n",
      "32       8 °C       Light rain. Overcast.   7 km/h        ↑       71%   \n",
      "33       8 °C                   Overcast.   7 km/h        ↑       61%   \n",
      "34       9 °C                   Overcast.   6 km/h        ↑       50%   \n",
      "35       9 °C  Light rain. Mostly cloudy.  No wind        ↑       50%   \n",
      "36       9 °C              Mostly cloudy.  No wind        ↑       44%   \n",
      "37       9 °C             Passing clouds.   7 km/h        ↑       43%   \n",
      "\n",
      "   Visibility  \n",
      "0   1006 mbar  \n",
      "1   1005 mbar  \n",
      "2   1004 mbar  \n",
      "3   1003 mbar  \n",
      "4   1003 mbar  \n",
      "5   1002 mbar  \n",
      "6   1002 mbar  \n",
      "7   1002 mbar  \n",
      "8   1001 mbar  \n",
      "9   1001 mbar  \n",
      "10  1000 mbar  \n",
      "11   999 mbar  \n",
      "12   997 mbar  \n",
      "13   996 mbar  \n",
      "14   997 mbar  \n",
      "15   997 mbar  \n",
      "16   996 mbar  \n",
      "17   997 mbar  \n",
      "18   998 mbar  \n",
      "19   998 mbar  \n",
      "20   999 mbar  \n",
      "21   999 mbar  \n",
      "22  1000 mbar  \n",
      "23  1001 mbar  \n",
      "24  1003 mbar  \n",
      "25  1002 mbar  \n",
      "26  1003 mbar  \n",
      "27  1004 mbar  \n",
      "28  1006 mbar  \n",
      "29  1005 mbar  \n",
      "30  1007 mbar  \n",
      "31  1010 mbar  \n",
      "32  1010 mbar  \n",
      "33  1011 mbar  \n",
      "34  1012 mbar  \n",
      "35  1014 mbar  \n",
      "36  1014 mbar  \n",
      "37  1014 mbar  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "URL = \"https://www.timeanddate.com/weather/usa/new-york/historic\"\n",
    "\n",
    "# Send a GET request to fetch the HTML content\n",
    "response = requests.get(URL)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the weather data (adjust selector based on actual table structure)\n",
    "table = soup.find('table')  # You might need to add specific classes or IDs to locate the correct table\n",
    "\n",
    "# Check if the table is found\n",
    "if table:\n",
    "    # Extract table headers (column names)\n",
    "    headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "    # Print the headers for debugging\n",
    "    print(\"Extracted Headers:\", headers)\n",
    "else:\n",
    "    print(\"Table not found on the webpage.\")\n",
    "\n",
    "# List to store scraped data\n",
    "web_scraped_data = []\n",
    "\n",
    "# Loop through \n",
    "for row in rows[1:]:  # Skip the header row\n",
    "    columns = row.find_all('td')  # Find all table data cells\n",
    "    \n",
    "    if len(columns) >= 7:  # Ensure there are enough columns\n",
    "        try:\n",
    "            # Extract and clean the data for each column\n",
    "            time = columns[0].text.strip()\n",
    "            temp = columns[1].text.strip()  \n",
    "            weather = columns[2].text.strip()\n",
    "            wind = columns[3].text.strip()\n",
    "            humidity = columns[4].text.strip()\n",
    "            barometer = columns[5].text.strip()\n",
    "            visibility = columns[6].text.strip()\n",
    "\n",
    "            # Append the data as a dictionary to the list\n",
    "            web_scraped_data.append({\n",
    "                'Time': time,\n",
    "                'Temp': temp,\n",
    "                'Weather': weather,\n",
    "                'Wind': wind,\n",
    "                'Humidity': humidity,\n",
    "                'Barometer': barometer,\n",
    "                'Visibility': visibility,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {[col.text.strip() for col in columns]}, Error: {e}\")\n",
    "\n",
    "# Convert the list of dictionaries into a Pandas DataFrame\n",
    "if web_scraped_data:\n",
    "    web_scraping_df = pd.DataFrame(web_scraped_data)\n",
    "    print(web_scraping_df)\n",
    "else:\n",
    "    print(\"No valid data was scraped.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
