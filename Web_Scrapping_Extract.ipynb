{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data from weather web using web scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Headers: ['', 'Temperature', 'Humidity', 'Pressure', 'High', 'Low', 'Average']\n",
      "     Temp            Weather     Wind Humidity  Barometer Visibility\n",
      "0    1 °C             Clear.   7 km/h      40%  1019 mbar      16 km\n",
      "1    1 °C             Clear.  13 km/h      38%  1019 mbar      16 km\n",
      "2    1 °C             Clear.   6 km/h      38%  1019 mbar      16 km\n",
      "3    1 °C             Clear.  13 km/h      35%  1019 mbar      16 km\n",
      "4    1 °C             Clear.  13 km/h      35%  1018 mbar      16 km\n",
      "5    2 °C             Clear.   7 km/h      34%  1018 mbar      16 km\n",
      "6    2 °C    Passing clouds.  17 km/h      32%  1018 mbar      16 km\n",
      "7    2 °C  Scattered clouds.      N/A      34%  1017 mbar      16 km\n",
      "8    3 °C             Sunny.  20 km/h      31%  1017 mbar      16 km\n",
      "9    3 °C             Sunny.  20 km/h      31%  1017 mbar      16 km\n",
      "10   2 °C             Sunny.  13 km/h      37%  1017 mbar      16 km\n",
      "11   1 °C             Sunny.      N/A      40%  1018 mbar      16 km\n",
      "12   0 °C             Sunny.      N/A      43%  1019 mbar      16 km\n",
      "13  -2 °C             Sunny.  11 km/h      49%  1019 mbar      16 km\n",
      "14  -2 °C             Sunny.  15 km/h      51%  1020 mbar      16 km\n",
      "15  -2 °C             Sunny.      N/A      53%  1019 mbar      16 km\n",
      "16  -3 °C             Clear.      N/A      53%  1019 mbar      16 km\n",
      "17  -3 °C             Clear.   7 km/h      51%  1019 mbar      16 km\n",
      "18  -3 °C             Clear.      N/A      49%  1019 mbar      16 km\n",
      "19  -2 °C             Clear.   7 km/h      49%  1019 mbar      16 km\n",
      "20  -2 °C             Clear.  15 km/h      51%  1019 mbar      16 km\n",
      "21  -2 °C             Clear.   7 km/h      49%  1019 mbar      16 km\n",
      "22  -2 °C             Clear.  11 km/h      49%  1018 mbar      16 km\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.timeanddate.com/weather/usa/new-york/historic\"\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all table rows\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "# Find the table containing the weather data (adjust selector based on actual table structure)\n",
    "table = soup.find('table')\n",
    "\n",
    "# Check if the table is found\n",
    "if table:\n",
    "    # Extract table headers (column names)\n",
    "    headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "    # Print the headers for debugging\n",
    "    print(\"Extracted Headers:\", headers)\n",
    "else:\n",
    "    print(\"Table not found on the webpage.\")\n",
    "\n",
    "\n",
    "# List to store scraped data\n",
    "web_scraped_data = []\n",
    "\n",
    "# Loop through \n",
    "for row in rows[1:]: \n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    if len(columns) >= 7:  # Ensure there are enough columns\n",
    "        try:\n",
    "            # Extract and clean the data for each column\n",
    "            temp = columns[1].text.strip()  \n",
    "            weather = columns[2].text.strip()\n",
    "            wind = columns[3].text.strip()\n",
    "            humidity = columns[5].text.strip()\n",
    "            barometer = columns[6].text.strip()\n",
    "            visibility = columns[7].text.strip()\n",
    "\n",
    "            # Append the data as a dictionary to the list\n",
    "            web_scraped_data.append({\n",
    "                'Temp': temp,\n",
    "                'Weather': weather,\n",
    "                'Wind': wind,\n",
    "                'Humidity': humidity,\n",
    "                'Barometer': barometer,\n",
    "                'Visibility': visibility,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {[col.text.strip() for col in columns]}, Error: {e}\")\n",
    "\n",
    "# Convert the list of dictionaries into a Pandas DataFrame\n",
    "if web_scraped_data:\n",
    "    web_scraping_df = pd.DataFrame(web_scraped_data)\n",
    "    print(web_scraping_df)\n",
    "else:\n",
    "    print(\"No valid data was scraped.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully inserted into the database.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Database connection parameters\n",
    "DB_PARAMS = {\n",
    "    'dbname': 'weather',\n",
    "    'user': 'postgres',\n",
    "    'password': 'KARU55bime22',\n",
    "    'host': 'localhost',  # Or your database host\n",
    "    'port': '5432',       # Default PostgreSQL port\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(**DB_PARAMS)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # SQL query to insert data into the weather_data table\n",
    "    insert_query = sql.SQL(\"\"\"\n",
    "        INSERT INTO weather_details (temp, weather, wind, humidity, barometer, visibility)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\")\n",
    "    \n",
    "    # Insert each row of the DataFrame into the database\n",
    "    for _, row in web_scraping_df.iterrows():\n",
    "        cursor.execute(insert_query, (\n",
    "            row['Temp'], \n",
    "            row['Weather'], \n",
    "            row['Wind'], \n",
    "            row['Humidity'], \n",
    "            row['Barometer'], \n",
    "            row['Visibility']\n",
    "        ))\n",
    "    \n",
    "    # Commit the transaction\n",
    "    conn.commit()\n",
    "    print(\"Data successfully inserted into the database.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error while inserting data: {e}\")\n",
    "    \n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Headers: ['#', 'Country,Other', 'TotalCases', 'NewCases', 'TotalDeaths', 'NewDeaths', 'TotalRecovered', 'NewRecovered', 'ActiveCases', 'Serious,Critical', 'Tot\\xa0Cases/1M pop', 'Deaths/1M pop', 'TotalTests', 'Tests/\\n1M pop', 'Population', 'Continent', '1 Caseevery X ppl', '1 Deathevery X ppl', '1 Testevery X ppl', 'New Cases/1M pop', 'New Deaths/1M pop', 'Active Cases/1M pop']\n",
      "      Country,Other   TotalCases TotalDeaths NewCases NewDeaths  \\\n",
      "0     North America  131,889,132   1,695,941                      \n",
      "1              Asia  221,500,265   1,553,662                      \n",
      "2            Europe  253,406,198   2,101,824                      \n",
      "3     South America   70,200,879   1,367,332                      \n",
      "4           Oceania   14,895,771      33,015                      \n",
      "..              ...          ...         ...      ...       ...   \n",
      "234         Tokelau           80                                  \n",
      "235    Vatican City           29                                  \n",
      "236  Western Sahara           10           1                      \n",
      "237      MS Zaandam            9           2                      \n",
      "238           China      503,302       5,272                      \n",
      "\n",
      "    TotalRecovered ActiveCases Deaths/1M pop     Population  \n",
      "0      127,665,129   2,528,062                               \n",
      "1      205,673,091  14,273,512                               \n",
      "2      248,754,104   2,550,270                               \n",
      "3       66,683,585   2,149,962                               \n",
      "4       14,752,388     110,368                               \n",
      "..             ...         ...           ...            ...  \n",
      "234                         80                        1,378  \n",
      "235             29           0                          799  \n",
      "236              9           0             2        626,161  \n",
      "237              7           0                               \n",
      "238        379,053     118,977             4  1,448,471,400  \n",
      "\n",
      "[239 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the COVID-19 data webpage\n",
    "URL = \"https://www.worldometers.info/coronavirus/\"\n",
    "\n",
    "# Send a GET request to fetch the webpage content\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the COVID-19 data\n",
    "table = soup.find('table', id='main_table_countries_today')\n",
    "\n",
    "# Extract table headers (column names)\n",
    "headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "# Debugging: Print extracted headers\n",
    "print(\"Extracted Headers:\", headers)\n",
    "\n",
    "# Define the columns of interest (match with extracted headers)\n",
    "desired_columns = [\n",
    "    \"Country,Other\",\n",
    "    \"TotalCases\",\n",
    "    \"TotalDeaths\",\n",
    "    \"NewCases\",\n",
    "    \"NewDeaths\",\n",
    "    \"TotalRecovered\",\n",
    "    \"ActiveCases\",\n",
    "    \"Deaths/1M pop\",\n",
    "    \"Population\"\n",
    "]\n",
    "\n",
    "# Find all rows in the table\n",
    "rows = table.find('tbody').find_all('tr')\n",
    "\n",
    "# List to store scraped data\n",
    "covid_data = []\n",
    "\n",
    "# Iterate through the rows and extract data\n",
    "for row in rows:\n",
    "    columns = row.find_all('td')\n",
    "    if columns:\n",
    "        data = [col.text.strip() for col in columns]\n",
    "        if len(data) >= len(headers):\n",
    "            covid_row = {headers[i]: data[i] for i in range(len(headers)) if headers[i] in desired_columns}\n",
    "            covid_data.append(covid_row)\n",
    "\n",
    "# Convert the list of dictionaries into a Pandas DataFrame\n",
    "covid_df = pd.DataFrame(covid_data)\n",
    "\n",
    "# Keep only the desired columns\n",
    "available_columns = [col for col in desired_columns if col in covid_df.columns]\n",
    "covid_df = covid_df[available_columns]\n",
    "\n",
    "print(covid_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n",
      "PostgreSQL connection closed.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# PostgreSQL database connection details\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"covid\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"KARU55bime22\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "try:\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create table if it doesn't exist\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS covid_history (\n",
    "        country TEXT,\n",
    "        total_cases BIGINT,\n",
    "        total_deaths BIGINT,\n",
    "        new_cases BIGINT,\n",
    "        new_deaths BIGINT,\n",
    "        total_recovered BIGINT,\n",
    "        active_cases BIGINT,\n",
    "        deaths_per_million FLOAT,\n",
    "        population BIGINT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Insert data into the database\n",
    "    for _, row in covid_df.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO covid_history (country, total_cases, total_deaths, new_cases, new_deaths, total_recovered, active_cases, deaths_per_million, population)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (country) DO NOTHING\n",
    "        \"\"\", (\n",
    "            row.get(\"Country,Other\"),\n",
    "            row.get(\"TotalCases\"),\n",
    "            row.get(\"TotalDeaths\"),\n",
    "            row.get(\"NewCases\"),\n",
    "            row.get(\"NewDeaths\"),\n",
    "            row.get(\"TotalRecovered\"),\n",
    "            row.get(\"ActiveCases\"),\n",
    "            row.get(\"Deaths/1M pop\"),\n",
    "            row.get(\"Population\")\n",
    "        ))\n",
    "\n",
    "    # Commit changes\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error while connecting to PostgreSQL:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"PostgreSQL connection closed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
