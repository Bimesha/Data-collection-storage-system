{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country/Region            0\n",
      "Confirmed                 0\n",
      "Deaths                    0\n",
      "Recovered                 0\n",
      "Active                    0\n",
      "New cases                 0\n",
      "New deaths                0\n",
      "New recovered             0\n",
      "Deaths / 100 Cases        0\n",
      "Recovered / 100 Cases     0\n",
      "Deaths / 100 Recovered    0\n",
      "Confirmed last week       0\n",
      "1 week change             0\n",
      "1 week % increase         0\n",
      "WHO Region                0\n",
      "dtype: int64\n",
      "Country/Region             object\n",
      "Confirmed                   int64\n",
      "Deaths                      int64\n",
      "Recovered                   int64\n",
      "Active                      int64\n",
      "New cases                   int64\n",
      "New deaths                  int64\n",
      "New recovered               int64\n",
      "Deaths / 100 Cases        float64\n",
      "Recovered / 100 Cases     float64\n",
      "Deaths / 100 Recovered    float64\n",
      "Confirmed last week         int64\n",
      "1 week change               int64\n",
      "1 week % increase         float64\n",
      "WHO Region                 object\n",
      "dtype: object\n",
      "[('Afghanistan', 36263, 1269, 25198, 9796, 106, 10, 18, 3.5, 69.49, 5.04, 35526, 737, 2.07, 'Eastern Mediterranean'), ('Albania', 4880, 144, 2745, 1991, 117, 6, 63, 2.95, 56.25, 5.25, 4171, 709, 17.0, 'Europe'), ('Algeria', 27973, 1163, 18837, 7973, 616, 8, 749, 4.16, 67.34, 6.17, 23691, 4282, 18.07, 'Africa'), ('Andorra', 907, 52, 803, 52, 10, 0, 0, 5.73, 88.53, 6.48, 884, 23, 2.6, 'Europe'), ('Angola', 950, 41, 242, 667, 18, 1, 0, 4.32, 25.47, 16.94, 749, 201, 26.84, 'Africa')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "#load the csv file to pandas dataframe\n",
    "df = pd.read_csv('covid.csv')\n",
    "\n",
    "#display the details in a table\n",
    "df.head()\n",
    "\n",
    "#check for the missing values\n",
    "missing_values =df.isnull().sum()\n",
    "data_types = df.dtypes\n",
    "\n",
    "print(missing_values)\n",
    "print(data_types)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('covid.csv')  # Replace 'covid_data.csv' with your actual CSV file\n",
    "\n",
    "# Adjust column names to match the database structure\n",
    "df.columns = [\n",
    "    'country_region', 'confirmed', 'deaths', 'recovered', 'active', \n",
    "    'new_cases', 'new_deaths', 'new_recovered', 'deaths_per_100_cases', \n",
    "    'recovered_per_100_cases', 'deaths_per_100_recovered', \n",
    "    'confirmed_last_week', 'one_week_change', 'one_week_percent_increase', \n",
    "    'who_region'\n",
    "]\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"covid\",  # Replace with your database name\n",
    "    user=\"postgres\",   # Replace with your username\n",
    "    password=\"KARU55bime22\",  # Replace with your password\n",
    "    host=\"localhost\",  # Replace with your PostgreSQL host\n",
    "    port=\"5432\"        # Default PostgreSQL port\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the covid_data table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS covid_data (\n",
    "    country_region VARCHAR(100),\n",
    "    confirmed BIGINT,\n",
    "    deaths BIGINT,\n",
    "    recovered BIGINT,\n",
    "    active BIGINT,\n",
    "    new_cases BIGINT,\n",
    "    new_deaths BIGINT,\n",
    "    new_recovered BIGINT,\n",
    "    deaths_per_100_cases FLOAT,\n",
    "    recovered_per_100_cases FLOAT,\n",
    "    deaths_per_100_recovered FLOAT,\n",
    "    confirmed_last_week BIGINT,\n",
    "    one_week_change BIGINT,\n",
    "    one_week_percent_increase FLOAT,\n",
    "    who_region VARCHAR(50)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Insert data into the table\n",
    "for index, row in df.iterrows():\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO covid_data (\n",
    "        country_region, confirmed, deaths, recovered, active, \n",
    "        new_cases, new_deaths, new_recovered, deaths_per_100_cases, \n",
    "        recovered_per_100_cases, deaths_per_100_recovered, \n",
    "        confirmed_last_week, one_week_change, one_week_percent_increase, \n",
    "        who_region\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Query the database to check the contents\n",
    "select_query = \"SELECT * FROM covid_data LIMIT 5;\"\n",
    "cursor.execute(select_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Date                0\n",
      "Summary                       0\n",
      "Precip Type                 517\n",
      "Temperature (C)               0\n",
      "Apparent Temperature (C)      0\n",
      "Humidity                      0\n",
      "Wind Speed (km/h)             0\n",
      "Wind Bearing (degrees)        0\n",
      "Visibility (km)               0\n",
      "Loud Cover                    0\n",
      "Pressure (millibars)          0\n",
      "Daily Summary                 0\n",
      "dtype: int64\n",
      "Formatted Date               object\n",
      "Summary                      object\n",
      "Precip Type                  object\n",
      "Temperature (C)             float64\n",
      "Apparent Temperature (C)    float64\n",
      "Humidity                    float64\n",
      "Wind Speed (km/h)           float64\n",
      "Wind Bearing (degrees)      float64\n",
      "Visibility (km)             float64\n",
      "Loud Cover                  float64\n",
      "Pressure (millibars)        float64\n",
      "Daily Summary                object\n",
      "dtype: object\n",
      "Index(['Formatted Date', 'Summary', 'Temperature (C)',\n",
      "       'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)',\n",
      "       'Wind Bearing (degrees)', 'Visibility (km)', 'Loud Cover',\n",
      "       'Pressure (millibars)', 'Daily Summary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_5396\\1561835385.py:23: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['Formatted Date'] = pd.to_datetime(df['Formatted Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2006, 4, 1), 'Partly Cloudy', 9.47222222222222, 7.388888888888887, 0.89, 14.1197, 251, 15.826300000000002, 0.0, 1015.13, 'Partly cloudy throughout the day.'), (datetime.date(2006, 4, 1), 'Partly Cloudy', 9.355555555555558, 7.227777777777776, 0.86, 14.2646, 259, 15.826300000000002, 0.0, 1015.63, 'Partly cloudy throughout the day.'), (datetime.date(2006, 4, 1), 'Mostly Cloudy', 9.377777777777778, 9.377777777777778, 0.89, 3.9284, 204, 14.9569, 0.0, 1015.94, 'Partly cloudy throughout the day.'), (datetime.date(2006, 4, 1), 'Partly Cloudy', 8.28888888888889, 5.944444444444446, 0.83, 14.1036, 269, 15.826300000000002, 0.0, 1016.41, 'Partly cloudy throughout the day.'), (datetime.date(2006, 4, 1), 'Mostly Cloudy', 8.755555555555553, 6.977777777777779, 0.83, 11.0446, 259, 15.826300000000002, 0.0, 1016.51, 'Partly cloudy throughout the day.')]\n"
     ]
    }
   ],
   "source": [
    "# Extrat data using weather csv file\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "df = pd.read_csv('weather.csv')\n",
    "df.head()\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "data_types = df.dtypes\n",
    "print(data_types)\n",
    "\n",
    "#drop the missing value column\n",
    "df.drop(columns=['Precip Type'], inplace=True)\n",
    "\n",
    "# Check it droped\n",
    "print(df.columns)\n",
    "\n",
    "# Convert 'Date' column to datetime type\n",
    "df['Formatted Date'] = pd.to_datetime(df['Formatted Date'])\n",
    "\n",
    "df.columns = [\n",
    "    'Formatted_Date', 'Summary', 'Temperature_C', \n",
    "    'Apparent_Temperature_C', 'Humidity', 'Wind_Speed_kmph', \n",
    "    'Wind_Bearing_degrees', 'Visibility_km', 'Cloud_Cover', \n",
    "    'Pressure_millibars', 'Daily_Summary'\n",
    "]\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"weather\",\n",
    "    user=\"postgres\",  \n",
    "    password=\"KARU55bime22\",  \n",
    "    host=\"localhost\",  \n",
    "    port=\"5432\" \n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the weather_data table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS weather_data (\n",
    "    Formatted_Date DATE,\n",
    "    Summary TEXT,\n",
    "    Temperature_C FLOAT,\n",
    "    Apparent_Temperature_C FLOAT,\n",
    "    Humidity FLOAT,\n",
    "    Wind_Speed_kmph FLOAT,\n",
    "    Wind_Bearing_degrees INT,\n",
    "    Visibility_km FLOAT,\n",
    "    Cloud_Cover FLOAT,\n",
    "    Pressure_millibars FLOAT,\n",
    "    Daily_Summary TEXT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Insert data into the table\n",
    "for index, row in df.iterrows():\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO weather_data (\n",
    "        Formatted_Date, Summary, Temperature_C, \n",
    "        Apparent_Temperature_C, Humidity, Wind_Speed_kmph, \n",
    "        Wind_Bearing_degrees, Visibility_km, Cloud_Cover, \n",
    "        Pressure_millibars, Daily_Summary\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Query the database to check the contents\n",
    "select_query = \"SELECT * FROM weather_data LIMIT 5;\"\n",
    "cursor.execute(select_query)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
